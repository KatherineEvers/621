---
title: '621 Homework #5'
author: "Katherine Evers"
date: "5/1/2020"
output: html_document
---

Overview

In this homework assignment, you will explore, analyze and model a data set containing information on approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine distribution companies after sampling a wine. These cases would be used to provide tasting samples to restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the
number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.

Your objective is to build a count regression model to predict the number of cases of wine that will be sold
given certain properties of the wine. HINT: Sometimes, the fact that a variable is missing is actually predictive of
the target. You can only use the variables given to you (or variables that you derive from the variables provided).
Below is a short description of the variables of interest in the data set:

Deliverables:
 A write-up submitted in PDF format. Your write-up should have four sections. Each one is described
below. You may assume you are addressing me as a fellow data scientist, so do not need to shy away
from technical details.
 Assigned predictions (number of cases of wine sold) for the evaluation data set.
 Include your R statistical programming code in an Appendix.

Write Up:

```{r packages, echo = FALSE, warning = FALSE, message = FALSE}
library(pander)
library(ggplot2)
library(dplyr)
library(corrplot)
library(reshape2)
library(kableExtra)


library(stringr)
library(tidyr)
library(caret)
library(pROC)
library(gridExtra)
library(pander)
library(mice)
library(car)

```

1. DATA EXPLORATION (25 Points)

Describe the size and the variables in the wine training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you aren’t doing your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median
b. Bar Chart or Box Plot of the data
c. Is the data correlated to the target variable (or to other variables?)
d. Are any of the variables missing and need to be imputed “fixed”?

```{r}
raw_data <- read.csv(url("https://raw.githubusercontent.com/KatherineEvers/Data-621/master/wine-training-data.csv"), header=TRUE)

dim(raw_data)

head(raw_data, 10)

scaled_data = data.frame(scale(raw_data[,!names(raw_data) %in% c("TARGET", "INDEX")]))

training_data<-raw_data[,c(2:16)]

mean(training_data$TARGET) #3.029074
var(training_data$TARGET) #3.710895 for possion mean=variance; var>mean overdispersion

#summary stats
sum_data <- summary(training_data)
pander(sum_data, split.table = 100, style = 'rmarkdown')

#missing values
training_data %>%
  summarise_all(list(~sum(is.na(.))))

missing.values <- training_data %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) 

missing.values
3359/12795 #STARS 0.2625244
1210/12795 #0.09456819 sulfates
682/12795 #0.05330207 total sulfur dioxide
653/12795 #0.05103556
647/12795 #0.05056663
638/12795 #0.04986323
616/12795 #0.04814381
395/12795 #0.03087143


#histograms
continuous_variables <-training_data[,c(2:12)]
histogram_data <- melt(continuous_variables)
ggplot(histogram_data, aes(value)) + 
  geom_bar(fill = "blue") + 
  facet_wrap(~variable, scales = "free") + 
  geom_histogram(bins=50)

#bar charts
discrete_variables <-training_data[,c(1,13:15)]

discrete_variables <- discrete_variables %>% mutate(
    TARGET = as.factor(TARGET),
    LabelAppeal = as.factor(LabelAppeal),
    AcidIndex = as.factor(AcidIndex ),
    STARS = as.factor(STARS))

g <- ggplot(discrete_variables , aes(TARGET))
g + geom_bar(aes(fill = TARGET)) + ggtitle("Target Bar Chart") 

g <- ggplot(discrete_variables , aes(LabelAppeal))
g + geom_bar(aes(fill = TARGET)) + ggtitle("Label Appeal Bar Chart") 

g <- ggplot(discrete_variables , aes(AcidIndex))
g + geom_bar(aes(fill = TARGET)) + ggtitle("Acid Index Bar Chart") 

g <- ggplot(discrete_variables , aes(STARS))
g + geom_bar(aes(fill = TARGET)) + ggtitle("Stars Bar Chart") 


#box plots
raw_data %>% dplyr::select(everything()) %>% tidyr::gather("id", "value",2:16) %>% 
  ggplot(., aes(x = id, y = value)) +geom_boxplot() + coord_flip() 

#correlation
cor_data <- data.frame(lapply(training_data, function(x) as.numeric(as.factor(x))))
corrplot(cor(dplyr::select(drop_na(cor_data), everything())), type = "lower")
```


2. DATA PREPARATION (25 Points)

Describe how you have transformed the data by changing the original variables or creating new variables. If you
did transform the data or create new variables, discuss why you did this. Here are some possible transformations.
a. Fix missing values (maybe with a Mean or Median value)
b. Create flags to suggest if a variable was missing
c. Transform data by putting it into buckets
d. Mathematical transforms such as log or square root (or use Box-Cox)
e. Combine variables (such as ratios or adding or multiplying) to create new variables

```{r}
#replace missing with mean
fillMissing <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
complete_data <- replace(training_data, TRUE, lapply(training_data, fillMissing))

transform_data <- training_data
transform_data$TARGET[transform_data$TARGET == 0] <- 0.5
transform_data <- transform_data %>% mutate_at(c("TARGET"), log)

hist(transform_data$TARGET)

#buckets
labelappeal <- ifelse(complete_data$LabelAppeal > 0, 'POSITIVE', ifelse(complete_data$LabelAppeal == 0, 'NEUTRAL', 'NEGATIVE'))

pH <- ifelse(complete_data$pH >= 3, 'ACIDIC', 'VERY ACIDIC')

complete_data_transformed <- complete_data[,!names(complete_data) %in% c('pH','LabelAppeal')]
complete_data_transformed$LabelAppeal <- labelappeal
complete_data_transformed$pH <- pH

table(labelappeal)
table(pH)
```


3. BUILD MODELS (25 Points)

Using the training data set, build at least two different poisson regression models, at least two different negative binomial regression models, and at least two multiple linear regression models, using different variables (or the same variables with different transformations). Sometimes poisson and negative binomial regression models give the same results. If that is the case, comment on that. Consider changing the input variables if that occurs so that you get different models. Although not covered in class, you may also want to consider building zero-inflated poisson and negative binomial regression models. You may select the variables manually, use an approach such as Forward or Stepwise, use a different approach such as trees, or use a combination of techniques. Describe the techniques you used. If you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done.

Discuss the coefficients in the models, do they make sense? In this case, about the only thing you can comment on is the number of stars and the wine label appeal. However, you might comment on the coefficient and magnitude of variables and how they are similar or different from model to model. For example, you might say “pH seems to have a major positive impact in my poisson regression model, but a negative effect in my multiple linear regression model”. Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.

```{r}
train_scaled_no_target = data.frame(scale(complete_data[,2:ncol(complete_data)]))
train_scaled = data.frame(TARGET = complete_data$TARGET, train_scaled_no_target)

train_scaled
```

```{r}
set.seed(100)

scaled_index = createDataPartition(train_scaled$TARGET, p = 0.8, list = F)

train = train_scaled[scaled_index,]
test = train_scaled[-scaled_index,]

#split predictor variables from response variables
target_train = train[,2:ncol(train)]
target_test = test[,2:ncol(test)]

target_train = train[,c(1:ncol(train))]
target_test = test[,c(1:ncol(test))]


train_nonzeros = target_train[target_train$TARGET != 0,]
```

```{r}
poisson_model_1 <- glm(TARGET ~ ., family=poisson, data=complete_data) #AIC: 50483
poisson_model_1 <- step(poisson_model_1, direction="backward")

poisson_model_1 <- glm(TARGET ~ ., family=poisson, data=target_train) #AIC: 40365

summary(poisson_model_1)


poisson_model_2 <- glm(TARGET ~ VolatileAcidity  + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density+ pH+ Sulphates + Alcohol + LabelAppeal + AcidIndex + STARS, family=poisson, data=target_train)

summary(poisson_model_2) #AIC: 40363

training.data <- data.frame(x.linear, y.linear)
training.model <- lm(training.data)
mean((target_train - predict(training.model))^2)

mean((test_set$y - predict.lm(model, test_set)) ^ 2)

poisson_model_3 <- glm(TARGET ~ VolatileAcidity +  FreeSulfurDioxide + TotalSulfurDioxide + Alcohol + LabelAppeal + AcidIndex + STARS, family=poisson, data=target_train)
summary(poisson_model_3) #AIC: 40394

#poisson_model_3 <- glm(TARGET ~ VolatileAcidity + LabelAppeal + AcidIndex + STARS, family=poisson, data=complete_data)
#summary(poisson_model_3) #AIC: 50565

poisson_model_3 <- glm(TARGET ~ LabelAppeal + STARS, family=poisson, data=complete_data)
poisson_model_3 <- glm(TARGET ~ LabelAppeal + STARS, family=poisson, data=complete_data_transformed)
summary(poisson_model_3)
```

4. SELECT MODELS (25 Points)

Decide on the criteria for selecting the best count regression model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your models.
For the count regression model, will you use a metric such as AIC, average squared error, etc.? Be sure to
explain how you can make inferences from the model, and discuss other relevant model output. If you like the
multiple linear regression model the best, please say why. However, you must select a count regression model for model deployment. Using the training data set, evaluate the performance of the count regression model. Make predictions using the evaluation data set.

```{r}
#train elastic net linear regression model
set.seed(100)

glm_net_regression = train(
  TARGET ~ ., data = train_nonzeros,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneLength = 50
)


#make predictions
glm_results = predict(poisson_model_2, newdata = target_test)


glm_results_df = data.frame(probs = glm_results)
glm_results_df$predictions = 0
glm_results_df$predictions[glm_results_df$probs >= 0.5] = 1
glm_results_df$predictions = as.factor(glm_results_df$predictions)



#roc curve
roc_output = roc(target_test$TARGET,glm_results_df$probs)

plot(roc_output, print.thres = "best", print.auc = T, xlim = c(1,0), col = "red", main = "ROC Curve")

caret::confusionMatrix(glm_results$predictions,target_test$TARGET, positive = "1")

aic1 <- poisson_model_1$aic
aic2 <- poisson_model_2$aic
aic3 <- poisson_model_3$aic
mse1 <- mean((target_train$TARGET - predict(poisson_model_1))^2)
mse2 <- mean((target_train$TARGET - predict(poisson_model_2))^2)
mse3 <- mean((target_train$TARGET - predict(poisson_model_3))^2) #7.053306
mse <- list(mse1,mse2, mse3) #7.049432
aic <- list(aic1,aic2, aic3)

aic_mse_table <- rbind(mse, aic)
colnames(aic_mse_table) <- c("Model 1", "Model 2", "Model 3")
aic_mse_table 



```

